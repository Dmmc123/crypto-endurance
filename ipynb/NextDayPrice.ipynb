{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import wandb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-14T11:40:07.548354481Z",
     "start_time": "2023-07-14T11:40:06.582681364Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1216 7 7\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(\"../datasets/BTC-USD.csv\")\n",
    "# define features and target\n",
    "look_back = 20\n",
    "feature_df = df.drop(columns=\"Date\", axis=1)\n",
    "features = []\n",
    "targets = []\n",
    "for i in range(look_back, len(df) - 1):\n",
    "    features.append(feature_df.values[i-look_back:i])\n",
    "    price_delta = df[\"Close\"].values[i+1] - df[\"Close\"].values[i]\n",
    "    targets.append(0 if price_delta < 0 else 1)\n",
    "# convert to numpy arrays for use with XGBoost\n",
    "features = np.array(features)\n",
    "targets = np.array(targets)\n",
    "features_flattened = features.reshape(features.shape[0], -1)\n",
    "# split the data into train/dev/test splits\n",
    "X_train, X_dev_test, y_train, y_dev_test = train_test_split(\n",
    "    features_flattened, targets, test_size=14, shuffle=False\n",
    ")\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(\n",
    "    X_dev_test, y_dev_test, test_size=7, shuffle=False\n",
    ")\n",
    "# create regression matrices\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_dev = xgb.DMatrix(X_dev, label=y_dev)\n",
    "d_test = xgb.DMatrix(X_test, label=y_test)\n",
    "print(d_train.num_row(), d_dev.num_row(), d_test.num_row())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-14T11:50:06.273894704Z",
     "start_time": "2023-07-14T11:50:06.230314756Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from random import shuffle\n",
    "import tqdm\n",
    "hp = [\n",
    "    [50, 100, 150, 200],  # num_boost_round\n",
    "    [0.01, 0.05, 0.1, 0.15, 0.2],  # learning_rate\n",
    "    [3, 4, 5, 6, 7, 8, 9, 10],  # max_depth\n",
    "    [0.5, 0.6, 0.7, 0.8, 0.9, 1],  # subsample\n",
    "    [0.5, 0.6, 0.7, 0.8, 0.9, 1],  # colsample_bytree\n",
    "]\n",
    "n_rounds = 100\n",
    "hps = list(product(*hp))\n",
    "shuffle(hps)\n",
    "print(len(hps))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '2'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "for num_boost_round, learning_rate, max_depth, subsample, colsample_bytree in tqdm.tqdm(hps[:n_rounds], \"Grid search (random sampling)\"):\n",
    "    # configure the run\n",
    "    training_params = {\n",
    "        \"objective\": \"reg:logistic\",\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree\n",
    "    }\n",
    "    run_config = {\n",
    "        \"num_boost_round\": num_boost_round,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree\n",
    "    }\n",
    "    run = wandb.init(project=\"cp-xgb-ndt\", config=run_config)\n",
    "    # train\n",
    "    model = xgb.train(\n",
    "        params=training_params,\n",
    "        dtrain=d_train,\n",
    "        num_boost_round=num_boost_round\n",
    "    )\n",
    "    # log the rmse\n",
    "    y_pred_dev = model.predict(d_dev)\n",
    "    y_pred_train = model.predict(d_train)\n",
    "    rmse_dev = f1_score(y_dev, np.round(y_pred_dev))\n",
    "    rmse_train = f1_score(y_train, np.round(y_pred_train))\n",
    "    run.log({\"train_f1\": rmse_train, \"dev_f1\": rmse_dev})\n",
    "    run.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save_model(\"xgb_next_day_trend.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
